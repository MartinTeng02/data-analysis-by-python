{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python\n",
    "## pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **整数索引问题**：Series 对象默认是按照标签索引.a的index其实也被截取了，那么如果对b索引，如果b[2]，其实取出来就是2，因为默认10是标签。采用*loc/iloc*方法即可对下标和标签进行区分。b.loc[2]，这里强制认为10是标签；b.iloc[0]，这里强制认为10是下标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "dtype: int32\n",
      "2    2\n",
      "3    3\n",
      "dtype: int32\n",
      "a 2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from builtins import print\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "a=pd.Series(np.arange(4))\n",
    "b=a[2:,]\n",
    "print(a)\n",
    "print(b)\n",
    "print(b.loc[2]) #把2认为是标签，默认也是这么认为的\n",
    "print(b.iloc[0]) #把0认为是对应的下标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **数据对齐**：pandas在进行两个series对象运算时，会按照index对齐后进行计算.在numpy中，形状不一致的array是不能直接相加的，在pandas中不同长度的series对象可以相加，只不过多余的值会被标记为缺失值。如果长度一致，但index有不一致的，对应的值也会被标记为not number。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    33\n",
      "c    32\n",
      "d    35\n",
      "dtype: int64\n",
      "a    33.0\n",
      "b     NaN\n",
      "c    32.0\n",
      "d    35.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sr1=pd.Series([12,23,24],index=['c','a','d'])\n",
    "sr2=pd.Series([11,20,10],index=['d','c','a'])\n",
    "print(sr1+sr2)\n",
    "sr3=pd.Series([11,20,10,40],index=['d','c','a','b'])\n",
    "print(sr1+sr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **缺失值处理**：not number其实是一种缺失值，pandas提供了处理方法。\n",
    "判断是否是缺失值,可以用isnull/notnull方法，由于pd支持布尔索引，所以可以利用这个方法去掉缺失值。当然，有一个更直接的函数dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    False\n",
      "b     True\n",
      "c    False\n",
      "d    False\n",
      "dtype: bool\n",
      "a     True\n",
      "b    False\n",
      "c     True\n",
      "d     True\n",
      "dtype: bool\n",
      "a    33.0\n",
      "c    32.0\n",
      "d    35.0\n",
      "dtype: float64\n",
      "a    33.0\n",
      "c    32.0\n",
      "d    35.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sr=sr1+sr3\n",
    "print(sr.isnull())\n",
    "print(sr.notnull())\n",
    "print(sr[sr.notnull()])\n",
    "print(sr.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **缺失值填充**：使用fillna函数，将缺失值赋值为给定的参数。\n",
    "当然，需要注意无论对缺失值怎样处理，原来的Series是不会变的，要保存的话就重新创建一个变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    33.0\n",
      "b     0.0\n",
      "c    32.0\n",
      "d    35.0\n",
      "dtype: float64\n",
      "a    33.000000\n",
      "b    33.333333\n",
      "c    32.000000\n",
      "d    35.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(sr.fillna(0))\n",
    "print(sr.fillna(sr.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **切片索引**：用index获取行索引，columns获取列索引，values获取值，T进行转置，describe进行数据说明。对于一个df，其本质上是多个series作为列组合在一起，所以单一切片时自然默认是把列切出来。df切片只能切单一维度，列或行，并且切行的时候只能切多行，这也很好理解，因为切单行，输入一个参数，程序不知道是行还是列，根据前面的规则，默认按列查找。loc与iloc两个方法是应对行和列同时切片的方法，前者是按标签索引，后者是按位置索引，按照标签索引是很自然的方式，因此默认索引方式是loc，这个默认意思是对于输入对象认为是标签而非位置，比如df[3]是对列名为3而非第四列进行切片。在切片时，行和列的要求用逗号隔开要求即可，如果只想切行，后面的逗号冒号可以都不加（你或许认为这个解释了前面df也可以切行，但是只能切多行的原因，觉得是loc方法，但实际上df[1:3]，虽然是切多行，而且是按位置，并没有使用iloc方法，也能切出1到2行），只想切列的话，前面的冒号逗号要加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   one  two\n",
      "a    1    4\n",
      "b    2    5\n",
      "c    3    6\n",
      "1"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'one':[1,2,3],'two':[4,5,6]},index=['a','b','c'])\n",
    "print(df)\n",
    "print(df['one']['a'],end='')#先列后行，但是用了两次中括号，不推荐\n",
    "#以下注意区分\n",
    "df['one']#切第一列\n",
    "df[['one','two']]#索引两列\n",
    "df[1]#输入了数字，默认按列和标签查找，实际上不存在列名为1的列，就会报错\n",
    "df[1:2]#输入了位置的范围，并不会输出第一列，而是会输出第一行\n",
    "df['a':'b']#输入了标签的范围，会输出第一行和第二行\n",
    "df['one':'two']#仿照上面的，能不能索引列呢？答案是不行\n",
    "#以上对于df的直接切片可以理解为，由于没有引进loc/iloc等方法，所以默认除了df['one'],df[['one','two']]之外，都\n",
    "#将其认为是对行进行索引，以至于像df[1:2]，df['a':'b']这样对位置或标签进行索引，都能得到列。\n",
    "#也可以看到其混乱之处，并且如果出现整数索引，更是容易出错，所以强烈推荐loc/iloc方法进行索引。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **缺失值处理**：在进行缺失值处理时，大部分情况与series是相似的，但是也有不同。比如dropna方法，参数有df.dropna(axis=,how=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   one  two\n",
      "a  NaN  NaN\n",
      "b  NaN  5.0\n",
      "c  3.0  6.0\n",
      "   one  two\n",
      "b  NaN  5.0\n",
      "c  3.0  6.0\n",
      "   one  two\n",
      "c  3.0  6.0\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [a, b, c]\n"
     ]
    }
   ],
   "source": [
    "df.loc['a']=np.NAN\n",
    "df.loc['b','one']=np.NAN\n",
    "print(df)\n",
    "print(df.dropna(how='all')) #all参数就表示只有这一行全是缺失值时才drop\n",
    "print(df.dropna(how='any')) #any参数表示只要有缺失值就drop\n",
    "print(df.dropna(axis=1)) #axis参数默认是0，以行为x轴，所以drop时我们是省略掉一行，我们将其设置为1，这样drop会省略一列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **常用函数**：dataframe排序有按值排序和按索引排序两种,有缺失值的部分不参与排序，放在最后面（不论是升序还是降序）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>two</th>\n",
       "      <th>one</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   two  one\n",
       "a  NaN  NaN\n",
       "b  5.0  NaN\n",
       "c  6.0  3.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='two',ascending=False) #按照值并且是按列排序，降序\n",
    "df.sort_values(by='c',ascending=False,axis=1) #按照值并且是按行排序，降序\n",
    "df.sort_index(ascending=False,axis=1) #按照标签排序，降序，并且对列索引进行排序。由于行索引或者列索引都是只有一个，因此就不需要by参数了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 时间序列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **时间对象生成**：一般有两种情况，把输入的字符串转化为时间格式，或者是生成一个时间范围"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n",
       "               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n",
       "               '2023-01-09', '2023-01-10',\n",
       "               ...\n",
       "               '2023-12-23', '2023-12-24', '2023-12-25', '2023-12-26',\n",
       "               '2023-12-27', '2023-12-28', '2023-12-29', '2023-12-30',\n",
       "               '2023-12-31', '2024-01-01'],\n",
       "              dtype='datetime64[ns]', length=366, freq='D')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dateutil\n",
    "pd.to_datetime(['2023-10-01','6/12/1998','2049-JAN-01','12/30/2002'],format='mixed') #将format参数设置成mixed，就可以识别各种类型的数据，转化为时间索引\n",
    "pd.date_range('2023-01-01','2024-01-01',freq='D')#start开始时间，end结束时间，periods时间长度，freq时间频率，默认为D(ay)，可选H(our),W(eek),B(usiness),A(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **切片索引**：如果把时间序列对象作为series的index，切片也会变得很灵活"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023-01-01     0\n",
       "2023-01-02     1\n",
       "2023-01-03     2\n",
       "2023-01-04     3\n",
       "2023-01-05     4\n",
       "2023-01-06     5\n",
       "2023-01-07     6\n",
       "2023-01-08     7\n",
       "2023-01-09     8\n",
       "2023-01-10     9\n",
       "2023-01-11    10\n",
       "2023-01-12    11\n",
       "2023-01-13    12\n",
       "2023-01-14    13\n",
       "2023-01-15    14\n",
       "2023-01-16    15\n",
       "2023-01-17    16\n",
       "2023-01-18    17\n",
       "2023-01-19    18\n",
       "2023-01-20    19\n",
       "2023-01-21    20\n",
       "2023-01-22    21\n",
       "2023-01-23    22\n",
       "2023-01-24    23\n",
       "2023-01-25    24\n",
       "2023-01-26    25\n",
       "2023-01-27    26\n",
       "2023-01-28    27\n",
       "2023-01-29    28\n",
       "2023-01-30    29\n",
       "2023-01-31    30\n",
       "2023-02-01    31\n",
       "2023-02-02    32\n",
       "2023-02-03    33\n",
       "2023-02-04    34\n",
       "2023-02-05    35\n",
       "2023-02-06    36\n",
       "2023-02-07    37\n",
       "2023-02-08    38\n",
       "2023-02-09    39\n",
       "2023-02-10    40\n",
       "2023-02-11    41\n",
       "2023-02-12    42\n",
       "2023-02-13    43\n",
       "2023-02-14    44\n",
       "2023-02-15    45\n",
       "2023-02-16    46\n",
       "2023-02-17    47\n",
       "2023-02-18    48\n",
       "2023-02-19    49\n",
       "2023-02-20    50\n",
       "2023-02-21    51\n",
       "2023-02-22    52\n",
       "2023-02-23    53\n",
       "2023-02-24    54\n",
       "2023-02-25    55\n",
       "2023-02-26    56\n",
       "2023-02-27    57\n",
       "2023-02-28    58\n",
       "2023-03-01    59\n",
       "Freq: D, dtype: int32"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_Series=pd.Series(np.arange(100),index=pd.date_range('2023-01-01',periods=100,freq='D'))\n",
    "T_Series['2023-03'] #只选取3月份数据\n",
    "T_Series.resample('M').sum() #reample按照给定参数M，对每月数据进行抽取，sum函数求和\n",
    "T_Series.truncate(after='2023-3-01') #对三月份前的数据进行切片\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 文件处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **文件读取**：主要是pd.read_csv()函数，参数包含sep：指定分隔符；header=None就是说这个文件没有列名；names可以指定列名；index_col制定某一列为索引；parse_dates，如果等于True，就会把所有可以解释为时间的值转换为时间数据，也可以等于一个列表，比如['date']，把这一列数据变为时间变量；na_values，指定哪些数据是缺失值，也是传入一个列表"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
